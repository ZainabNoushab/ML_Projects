{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f48a46f",
   "metadata": {},
   "source": [
    "# Marketing Campaign Response Prediction (ML Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b4c55d",
   "metadata": {},
   "source": [
    "## Data Loading & Initial Exploration\n",
    "- Load dataset\n",
    "- Check structure, missing values, datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d92dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"marketing_campaign.csv\", sep='\\t')  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd784cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape:', df.shape)\n",
    "\n",
    "print('\\nColumns:')\n",
    "print(df.columns)\n",
    "print(df.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee4476",
   "metadata": {},
   "source": [
    "##  Data Cleaning\n",
    "- Fix date column\n",
    "- Handle missing income\n",
    "- Check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed94e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "df.fillna(df['Income'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4747cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Dt_Customer'].head()\n",
    "df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'], format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45299087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d785f",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- Customer Tenure\n",
    "- Age\n",
    "- Family Size\n",
    "- Total Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5759b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Customer Tenure (Days since joining)\n",
    "import datetime\n",
    "today = datetime.datetime.today()\n",
    "df['Customer_Tenure'] = (today - df['Dt_Customer']).dt.days\n",
    "\n",
    "# 2. Customer Age\n",
    "df['Age'] = 2025 - df['Year_Birth']  # Fixed typo in comment\n",
    "\n",
    "# 3. Family Size (Assuming 2 adults + kids at home)\n",
    "df['Family_Size'] = 2 + df['Kidhome'] + df['Teenhome']\n",
    "\n",
    "# 4. Total Spending \n",
    "spending_col = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
    "df['Total_Spending'] = df[spending_col].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafbf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Customer_Tenure', 'Age', 'Family_Size', 'Total_Spending']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ede62a",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "- Age distribution\n",
    "- Spending vs response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Plot 1: Age Distribution\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.hist(df['Age'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Customer Age', fontsize=14)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Plot 2: Total Spending by Campaign Response\n",
    "plt.subplot(3, 1, 2)\n",
    "avg_spend = df.groupby('Response')['Total_Spending'].mean()\n",
    "plt.bar(['No (0)', 'Yes (1)'], avg_spend, color=['salmon', 'lightgreen'])\n",
    "plt.title('Average Total Spending by Campaign Response')\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Average Spending')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07a212",
   "metadata": {},
   "source": [
    "## Business Questions\n",
    "\n",
    "1. **Which customer characteristics influence positive campaign response the most?**  \n",
    "   This will help identify which features (like age, income, spending) are most predictive of a “yes” response.\n",
    "\n",
    "2. **Do higher-spending customers respond better to marketing campaigns?**  \n",
    "   This will explore whether overall spending affects likelihood of response — helping prioritize customer segments.\n",
    "\n",
    "3. **How does customer age and income impact campaign response?**  \n",
    "   This will analyze the effect of age and income levels on engagement with the campaign.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e659d",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "- Encode variables\n",
    "- Train/test split\n",
    "- Train Logistic Regression & Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eb6f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['ID', 'Dt_Customer', 'Response'], axis=1)\n",
    "y = df['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "867fb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b989137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8013d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 1. Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Both models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2d2224",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "- Compare precision, recall, F1-score\n",
    "- Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b0255d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Evaluation:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       379\n",
      "           1       0.61      0.20      0.30        69\n",
      "\n",
      "    accuracy                           0.86       448\n",
      "   macro avg       0.74      0.59      0.61       448\n",
      "weighted avg       0.83      0.86      0.83       448\n",
      "\n",
      "Confusion Matrix:\n",
      " [[370   9]\n",
      " [ 55  14]]\n",
      "\n",
      "Decision Tree Evaluation:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       379\n",
      "           1       0.40      0.39      0.40        69\n",
      "\n",
      "    accuracy                           0.82       448\n",
      "   macro avg       0.65      0.64      0.64       448\n",
      "weighted avg       0.81      0.82      0.82       448\n",
      "\n",
      "Confusion Matrix:\n",
      " [[339  40]\n",
      " [ 42  27]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Logistic Regression predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression Evaluation:\\n\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "# Decision Tree predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "print(\"\\nDecision Tree Evaluation:\\n\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ffeb9",
   "metadata": {},
   "source": [
    "## Model Evaluation Summary\n",
    "\n",
    "We trained and compared two classification models to predict customer responses to a marketing campaign:\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Logistic Regression\n",
    "- **Accuracy:** 86%\n",
    "- **Precision (Class 1):** 0.61\n",
    "- **Recall (Class 1):** 0.20\n",
    "- **F1-Score (Class 1):** 0.30\n",
    "\n",
    "Logistic Regression performed well in identifying non-responders (class 0), but failed to correctly detect most actual responders. It missed 55 out of 69 responders, which is a significant limitation for marketing campaign effectiveness.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Decision Tree Classifier\n",
    "- **Accuracy:** 82%\n",
    "- **Precision (Class 1):** 0.40\n",
    "- **Recall (Class 1):** 0.39\n",
    "- **F1-Score (Class 1):** 0.40\n",
    "\n",
    "The Decision Tree model offered a better balance between identifying both responders and non-responders. It correctly identified 27 out of 69 responders, significantly outperforming Logistic Regression in that category.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "While Logistic Regression has a higher overall accuracy, the Decision Tree model is **more effective for campaign targeting**, as it captures more actual responders. This makes it the **preferred model for marketing strategy** in this case.\n",
    "\n",
    "**Final Model Selected:** Decision Tree Classifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
